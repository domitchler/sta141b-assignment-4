{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# STA 141B Assignment 4\n",
    "\n",
    "Due __Feb 22, 2019__ by 11:59pm. Submit by editing this file, committing the changes with git, and then pushing to your private GitHub repo for the assignment. This assignment will be graded according to the class rubric.\n",
    "\n",
    "Please do not rename this file or delete the exercise cells, because it will interfere with our grading tools. Put your answers in new cells after each exercise. You can make as many new cells as you like. Use code cells for code and Markdown cells for text. Answer all questions with complete sentences.\n",
    "\n",
    "The purpose of this assignment is to practice scraping data from web pages."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The San Francisco Chronicle\n",
    "\n",
    "In this assignment, you'll scrape text from [The San Francisco Chronicle](https://www.sfchronicle.com/) newspaper and then analyze the text.\n",
    "\n",
    "The Chronicle is organized by category into article lists. For example, there's a [Local](https://www.sfchronicle.com/local/) list, [Sports](https://www.sfchronicle.com/sports/) list, and [Food](https://www.sfchronicle.com/food/) list.\n",
    "\n",
    "The goal of exercises 1.1 - 1.3 is to scrape articles from the Chronicle for analysis in exercise 1.4."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "exercise"
    ]
   },
   "source": [
    "__Exercise 1.1.__ Write a function that extracts all of the links to articles in a Chronicle article list. The function should:\n",
    "\n",
    "* Have a parameter `url` for the URL of the article list.\n",
    "\n",
    "* Return a list of article URLs (each URL should be a string).\n",
    "\n",
    "Test your function on 2-3 different categories to make sure it works.\n",
    "\n",
    "Hints:\n",
    "\n",
    "* Be polite and save time by setting up [requests_cache](https://pypi.python.org/pypi/requests-cache) before you write your function.\n",
    "\n",
    "* You can use any of the XML/HTML parsing packages mentioned in class. Choose one and use it throughout the entire assignment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "exercise"
    ]
   },
   "source": [
    "__Exercise 1.2.__ Write a function that extracts data from a Chronicle article. The function should:\n",
    "\n",
    "* Have a parameter `url` for the URL of the article.\n",
    "\n",
    "* Return a dictionary with keys for:\n",
    "    + `url`: The URL of the article.\n",
    "    + `title`: The title of the article.\n",
    "    + `text`: The complete text of the article.\n",
    "    + `author`: The author's name (if available) or a suitable missing value.\n",
    "    + `date`: The date and time the article was published.\n",
    "    + `date_updated`: The date and time the article was last updated (if available) or a suitable missing value.\n",
    "\n",
    "For example, for [this article](https://www.sfchronicle.com/homeandgarden/article/Gardenlust-looks-at-best-21st-century-13580871.php) your function should return a dictionary with the form:\n",
    "```js\n",
    "{'url': 'https://www.sfchronicle.com/homeandgarden/article/Gardenlust-looks-at-best-21st-century-13580871.php',\n",
    " 'title': '‘Gardenlust’ looks at best 21st century gardens in the world',\n",
    " 'text': 'The book...',\n",
    " 'author': 'Pam Peirce',\n",
    " 'date': '2019-02-01T18:02:33+00:00',\n",
    " 'date_updated': '2019-02-01T18:12:53+00:00'}\n",
    "```\n",
    "The value of the `text` field is omitted here to save space. Your function should return the full text in the `text` field.\n",
    "\n",
    "Hints:\n",
    "\n",
    "* Many parsing packages allow you to delete elements from an HTML document. Deleting elements is one way to avoid extracting unwanted tags.\n",
    "* You can union multiple XPath paths with `|`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "exercise"
    ]
   },
   "source": [
    "__Exercise 1.3.__ Use your functions from exercises 1.1 and 1.2 to get data frames of articles for the \"Biz+Tech\" category as well as two other categories of your choosing (except for \"Vault: Archive\", \"Podcasts\", and \"In Depth\").\n",
    "\n",
    "Add a column to each that indicates the category, then combine them into one big data frame. Clean up the data, stripping excess whitespace and converting columns to appropriate dtypes.\n",
    "\n",
    "The `text` column of this data frame will be your corpus for natural language processing in exercise 1.4."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "exercise"
    ]
   },
   "source": [
    "__Exercise 1.4.__  What topics has the Chronicle covered recently? How does the category affect the topics? Support your analysis with visualizations.\n",
    "\n",
    "Hints:\n",
    "\n",
    "*   The [nltk book](http://www.nltk.org/book/) may be helpful here.\n",
    "\n",
    "*   This question will be easier to do after we've finished NLP in class."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
